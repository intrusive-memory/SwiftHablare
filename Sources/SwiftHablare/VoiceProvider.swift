//
//  VoiceProvider.swift
//  SwiftHablare
//
//  Protocol defining voice provider capabilities
//

import Foundation
import AVFoundation
#if canImport(SwiftUI)
import SwiftUI
#endif

/// Protocol defining voice provider capabilities
public protocol VoiceProvider: Sendable {
    /// Unique identifier for the provider
    var providerId: String { get }

    /// Display name for the provider
    var displayName: String { get }

    /// Whether this provider requires an API key
    var requiresAPIKey: Bool { get }

    /// MIME type of audio generated by this provider (e.g., "audio/x-aiff", "audio/mpeg")
    var mimeType: String { get }

    /// The default voice ID for this provider, if one exists.
    /// Returns `nil` for providers that have no meaningful default (e.g., Apple).
    var defaultVoiceId: String? { get }

    /// Check if the provider is properly configured
    func isConfigured() async -> Bool

    /// Fetch available voices from the provider
    /// - Parameter languageCode: Optional language code to filter voices (e.g., "en", "es", "fr").
    ///   If not provided, uses system language code as default.
    func fetchVoices(languageCode: String) async throws -> [Voice]

    /// Generate audio data from text using a specific voice
    /// - Parameters:
    ///   - text: The text to convert to speech
    ///   - voiceId: The voice identifier to use
    ///   - languageCode: The language code for generation (e.g., "en", "es", "fr").
    ///     Defaults to system language if not provided.
    func generateAudio(text: String, voiceId: String, languageCode: String) async throws -> Data

    /// Generate and process audio data with silence trimming and accurate duration measurement
    /// - Parameters:
    ///   - text: The text to convert to speech
    ///   - voiceId: The voice identifier to use
    ///   - languageCode: The language code for generation (e.g., "en", "es", "fr").
    ///     Defaults to system language if not provided.
    /// - Returns: Processed audio with trimmed silence and measured duration
    func generateProcessedAudio(text: String, voiceId: String, languageCode: String) async throws -> ProcessedAudio

    /// Estimate the duration (in seconds) of audio that would be generated from the given text
    func estimateDuration(text: String, voiceId: String) async -> TimeInterval

    /// Check if a specific voice is available for this provider
    /// - Parameter voiceId: The voice identifier to check
    /// - Returns: True if the voice is available, false otherwise
    func isVoiceAvailable(voiceId: String) async -> Bool

#if canImport(SwiftUI)
    /// Build the SwiftUI configuration panel for this provider
    ///
    /// Implementations should present any fields necessary to configure the
    /// provider (e.g., API keys). The view must invoke the `onConfigured`
    /// callback with `true` when configuration succeeds, or `false` if it
    /// fails or is cancelled.
    ///
    /// - Parameter onConfigured: Callback invoked when configuration
    ///   completes.
    /// - Returns: A type-erased SwiftUI view representing the configuration
    ///   panel.
    @MainActor
    func makeConfigurationView(onConfigured: @escaping (Bool) -> Void) -> AnyView
#endif
}

// MARK: - Default Implementations

extension VoiceProvider {
    /// Default: no default voice ID. Providers with a meaningful default override this.
    public var defaultVoiceId: String? { nil }

    /// Fetch available voices using system language code as default
    public func fetchVoices() async throws -> [Voice] {
        return try await fetchVoices(languageCode: LanguageCodeResolver.systemLanguageCode)
    }

    /// Generate audio using system language code as default
    public func generateAudio(text: String, voiceId: String) async throws -> Data {
        return try await generateAudio(text: text, voiceId: voiceId, languageCode: LanguageCodeResolver.systemLanguageCode)
    }

    /// Generate processed audio using system language code as default
    public func generateProcessedAudio(text: String, voiceId: String) async throws -> ProcessedAudio {
        return try await generateProcessedAudio(text: text, voiceId: voiceId, languageCode: LanguageCodeResolver.systemLanguageCode)
    }

    /// Default implementation: Generate raw audio and measure duration (no compression or trimming)
    ///
    /// This stores raw audio without M4A conversion to:
    /// - Avoid AVAssetExportSession failures on some platforms
    /// - Reduce generation time
    /// - Preserve audio quality
    /// - Defer compression until export time
    ///
    /// Providers can override this to add custom processing if needed.
    public func generateProcessedAudio(text: String, voiceId: String, languageCode: String) async throws -> ProcessedAudio {
        let rawAudio = try await generateAudio(text: text, voiceId: voiceId, languageCode: languageCode)
        let duration = try await measureDuration(audioData: rawAudio, mimeType: self.mimeType)

        return ProcessedAudio(
            audioData: rawAudio,
            durationSeconds: duration,
            trimmedStart: 0,
            trimmedEnd: 0,
            mimeType: self.mimeType  // Keep original format
        )
    }

    /// Measure audio duration from raw audio data
    private func measureDuration(audioData: Data, mimeType: String) async throws -> Double {
        // Determine file extension from MIME type
        let fileExtension = Self.fileExtension(for: mimeType)

        // Write to temp file to load with AVAsset
        let tempURL = FileManager.default.temporaryDirectory
            .appendingPathComponent(UUID().uuidString)
            .appendingPathExtension(fileExtension)

        try audioData.write(to: tempURL)
        defer { try? FileManager.default.removeItem(at: tempURL) }

        let asset = AVURLAsset(url: tempURL)
        let duration = try await asset.load(.duration)
        return duration.seconds
    }

    /// Get file extension from MIME type
    private static func fileExtension(for mimeType: String) -> String {
        let components = mimeType.split(separator: "/")
        guard components.count == 2 else { return "audio" }

        let subtype = String(components[1]).lowercased()

        switch subtype {
        case "mpeg", "mp3": return "mp3"
        case "mp4", "m4a": return "m4a"
        case "wav", "x-wav", "vnd.wave": return "wav"
        case "aiff", "x-aiff": return "aiff"
        case "pcm", "l16": return "wav"
        default: return subtype
        }
    }
}

/// Voice provider errors
public enum VoiceProviderError: LocalizedError, Sendable {
    case notConfigured
    case networkError(String)
    case invalidResponse
    case unsupportedProvider
    case notSupported
    case invalidRequest(String)

    public var errorDescription: String? {
        switch self {
        case .notConfigured:
            return "Voice provider is not configured. Please check your settings."
        case .networkError(let message):
            return "Network error: \(message)"
        case .invalidResponse:
            return "Invalid response from voice provider"
        case .unsupportedProvider:
            return "Unsupported voice provider"
        case .notSupported:
            return "Audio generation is not supported on this platform"
        case .invalidRequest(let message):
            return "Invalid request: \(message)"
        }
    }
}
