<div align="center">
  <img src="Resources/Hablare.png" alt="SwiftHablarÃ© Logo" width="200"/>
</div>

# SwiftHablarÃ©

[![Tests](https://github.com/intrusive-memory/SwiftHablare/actions/workflows/tests.yml/badge.svg)](https://github.com/intrusive-memory/SwiftHablare/actions/workflows/tests.yml)

**A unified Swift framework for integrating multiple AI services with automatic SwiftData persistence.**

SwiftHablarÃ© provides a consistent API for interacting with various AI service providers (text generation, audio synthesis, image generation, and more) while seamlessly storing results in SwiftData models. Currently focused on text-to-speech, with plans to expand to a comprehensive AI service integration framework.

## Current Features (v1.x)

- **Multiple TTS Provider Support**: Switch between Apple TTS and ElevenLabs
- **SwiftData Integration**: Built-in caching for voices and generated audio
- **Secure API Key Storage**: Uses Keychain for secure credential management
- **Async/Await API**: Modern Swift concurrency support
- **Audio File Management**: Generate, cache, and write audio files with ease

## Planned Features (v2.0)

- **Unified AI Service Interface**: Consistent API for OpenAI, Anthropic, Google AI, ElevenLabs, and more
- **Declarative SwiftData Mapping**: Providers and models declare their capabilities
- **Automatic Data Persistence**: AI-generated content automatically saved to SwiftData
- **Plugin Architecture**: Easy addition of new AI service providers
- **SwiftUI Components**: Pre-built configuration panels and generation UI
- **Multi-modal Support**: Text, audio, images, video, structured data, and embeddings

See [REQUIREMENTS.md](REQUIREMENTS.md) for the complete v2.0 vision and roadmap.

## Current Status

**UI Sprint Phase 1-2: Background Tasks & Screenplay Processing** âœ… Complete

SwiftHablarÃ© is currently undergoing a major rewrite (v2.0) to expand from a TTS-focused library to a comprehensive AI service integration framework. Phases 0-7 have established the core architecture, and the UI Sprint has now added a complete background task management system with screenplay processing capabilities. The library now includes 787 passing tests with 90%+ coverage and full macCatalyst compatibility.

See [METHODOLOGY.md](METHODOLOGY.md) for the complete development roadmap and [REQUIREMENTS.md](REQUIREMENTS.md) for detailed specifications.

### Completed in Phase 0-4
- âœ… Core protocol definitions (AIServiceProvider, AIGeneratable)
- âœ… Comprehensive error handling framework
- âœ… SwiftData model base classes for all content types
- âœ… Provider registry system (AIServiceManager)
- âœ… Provider capability querying
- âœ… SwiftData structure declaration validation
- âœ… Automatic persistence logic (AIPersistenceCoordinator)
- âœ… Response field binding and type conversion
- âœ… Caching system (AIResponseCache)
- âœ… Validation framework (AIContentValidator)
- âœ… Mock provider framework for testing
- âœ… **Thread-safe request management (AIRequestManager actor)**
- âœ… **Immutable response types (AIResponseData, ResponseContent)**
- âœ… **Request lifecycle tracking (pending â†’ executing â†’ completed/failed)**
- âœ… **Main actor data coordination (AIDataCoordinator)**
- âœ… **Zero Swift data race conditions**
- âœ… **Async/await request interface with status observation**
- âœ… **Batch request support with partial failure handling**
- âœ… **Secure keychain integration (SecureKeychainManager)**
- âœ… **Thread-safe credential management (AICredentialManager actor)**
- âœ… **Memory-safe credential handling (SecureString)**
- âœ… **Provider-specific validation (OpenAI, Anthropic, ElevenLabs)**
- âœ… **Credential lifecycle operations (store, retrieve, update, delete)**
- âœ… **Expiration tracking and automatic cleanup**
- âœ… **Real provider implementations (OpenAI, Anthropic, Apple Intelligence, ElevenLabs)**
- âœ… **Full API integration with secure credential management**
- âœ… **Multi-modal support (text generation, audio generation, on-device AI)**
- âœ… **Typed return data system with SwiftData persistence**
- âœ… **12 AI requestors across 4 content types (Text, Audio, Image, Embedding)**
- âœ… **Efficient storage with automatic file management (100KB thresholds)**
- âœ… **Binary serialization for embeddings (~75% size reduction)**
- âœ… **559 tests with 90%+ coverage across all core modules**
- âœ… **Swift 6.0 strict concurrency compliance**
- âœ… **Test infrastructure improvements (keychain, SwiftData, concurrency)**

### Recent Completion: Phase 6 Typed Return Data System âœ…
- âœ… **AIRequestor Protocol** - Standardized interface for typed data generation
- âœ… **4 Content Types** - Text, Audio, Image, and Embedding support
- âœ… **12 Requestors** - 8 OpenAI, 3 Anthropic, 1 ElevenLabs requestors
- âœ… **SwiftData Persistence** - Typed models for all content types
- âœ… **Efficient Storage** - Automatic threshold-based file management
  - Text: 50KB threshold with JSON serialization
  - Audio: 100KB threshold with binary format
  - Images: 100KB threshold with PNG format
  - Embeddings: 100KB threshold with custom binary format
- âœ… **Binary Serialization** - 75% size reduction for large embeddings
- âœ… **Cost Estimation** - Accurate cost tracking for all operations
- âœ… **402 Tests** - 100% pass rate across all sub-phases
- âœ… **Production Ready** - Comprehensive error handling and validation

**Supported Models**:
- **Text**: GPT-4, GPT-4 Turbo, GPT-3.5 Turbo, Claude 3.5 Sonnet, Claude 3 Opus/Haiku
- **Audio**: ElevenLabs TTS (11 voices with style support)
- **Image**: DALL-E 2, DALL-E 3 (with video aspect ratios)
- **Embedding**: text-embedding-3-small/large, text-embedding-ada-002

### Recent Completion: UI Sprint Phase 1-2 âœ…
- âœ… **Background Task System** - Observable state machine with queueing and progress tracking
- âœ… **Screenplay Processing** - SpeakableItemGenerationTask with 96.85% coverage
- âœ… **787 Tests** - Comprehensive test suite with 100% pass rate (up from 559)
- âœ… **90%+ Coverage** - All ScreenplaySpeech modules exceed 90% coverage
- âœ… **macCatalyst Support** - Full cross-platform compatibility
- âœ… **UI Components** - BackgroundTasksPalette, BackgroundTaskRow with Xcode previews
- âœ… **Quality Assurance** - Zero compilation errors, Swift 6 strict concurrency compliant

See [SCREENPLAY_UI_SPRINT_METHODOLOGY.md](Docs/SCREENPLAY_UI_SPRINT_METHODOLOGY.md) for the complete UI sprint plan.
See [PHASE_7D_COMPLETION_REPORT.md](Docs/Previous/PHASE_7D_COMPLETION_REPORT.md) and [PHASE_6_COMPLETION_SUMMARY.md](Docs/Previous/PHASE_6_COMPLETION_SUMMARY.md) for previous phase details.

### Next: UI Sprint Phase 3-4
- **Phase 3**: Character Mapping Models
  - CharacterVoiceMapping SwiftData model
  - Character detection and auto-mapping generator
  - Bidirectional voice assignment UI
- **Phase 4**: Core UI Scaffolding
  - Main screenplay speech view with tabs
  - BackgroundTasksPalette integration
  - ProviderPickerView for global provider selection
  - Screenplay tracking and filtering

## Requirements

- macOS 15.0+ / iOS 17.0+ / macCatalyst 15.0+
- Swift 6.0+
- Xcode 16.4+
- SwiftData

## Platform Support

SwiftHablarÃ© is designed to work seamlessly across Apple's platforms:

- **macOS 15.0+** - Full native macOS support
- **iOS 17.0+** - Full native iOS support
- **macCatalyst 15.0+** - Complete Catalyst compatibility

All UI components use cross-platform SwiftUI and color APIs, ensuring consistent behavior across platforms. No AppKit or UIKit dependencies in production code.

## Installation

**Note**: The v2.0 rewrite is in active development. For production use, please use v1.x releases.

### Swift Package Manager

```swift
dependencies: [
    .package(url: "https://github.com/intrusive-memory/SwiftHablare", from: "1.0.0")
]
```

## Documentation

- [CLAUDE.md](CLAUDE.md) - Comprehensive guide for AI assistants working on the project
- [CHANGELOG.md](CHANGELOG.md) - Detailed change log for all releases
- [AI_DEVELOPMENT_GUIDE.md](AI_DEVELOPMENT_GUIDE.md) - Development patterns and practices
- [AI_REFERENCE.md](AI_REFERENCE.md) - Quick reference for common tasks
- [REQUIREMENTS.md](REQUIREMENTS.md) - Complete v2.0 requirements and specifications
- [Docs/SCREENPLAY_UI_SPRINT_METHODOLOGY.md](Docs/SCREENPLAY_UI_SPRINT_METHODOLOGY.md) - UI sprint phases and methodology
- [Docs/SCREENPLAY_UI_DECISIONS.md](Docs/SCREENPLAY_UI_DECISIONS.md) - Critical UI design decisions

## Project Structure

```
SwiftHablare/
â”œâ”€â”€ Sources/SwiftHablare/
â”‚   â”œâ”€â”€ Core/                    # Core protocols and types âœ…
â”‚   â”œâ”€â”€ SwiftDataModels/         # General SwiftData models âœ… REORGANIZED
â”‚   â”‚   â”œâ”€â”€ AIGeneratedContent.swift
â”‚   â”‚   â”œâ”€â”€ GeneratedText.swift
â”‚   â”‚   â”œâ”€â”€ GeneratedAudio.swift
â”‚   â”‚   â”œâ”€â”€ GeneratedImage.swift
â”‚   â”‚   â”œâ”€â”€ GeneratedVideo.swift
â”‚   â”‚   â”œâ”€â”€ GeneratedStructuredData.swift
â”‚   â”‚   â”œâ”€â”€ VoiceModel.swift
â”‚   â”‚   â””â”€â”€ AudioFile.swift
â”‚   â”œâ”€â”€ ScreenplaySpeech/        # Screenplay processing âœ…
â”‚   â”‚   â”œâ”€â”€ Tasks/               # Background task system
â”‚   â”‚   â”œâ”€â”€ UI/                  # Task UI components
â”‚   â”‚   â”œâ”€â”€ Models/              # SpeakableItem, SpeakableAudio
â”‚   â”‚   â”œâ”€â”€ Processing/          # Screenplay processors
â”‚   â”‚   â””â”€â”€ Logic/               # Speech logic rules
â”‚   â”œâ”€â”€ TypedData/               # Typed data system âœ…
â”‚   â”‚   â”œâ”€â”€ Text/                # GeneratedTextRecord
â”‚   â”‚   â”œâ”€â”€ Audio/               # GeneratedAudioRecord
â”‚   â”‚   â”œâ”€â”€ Image/               # GeneratedImageRecord
â”‚   â”‚   â””â”€â”€ Embedding/           # GeneratedEmbeddingRecord
â”‚   â”œâ”€â”€ UI/                      # UI widgets (Catalyst-ready) âœ…
â”‚   â”œâ”€â”€ Providers/               # Voice & AI providers âœ…
â”‚   â””â”€â”€ [Other modules]
â”œâ”€â”€ Tests/SwiftHablareTests/
â”‚   â”œâ”€â”€ Core/                    # Core type tests âœ…
â”‚   â”œâ”€â”€ ScreenplaySpeech/        # Background task tests âœ…
â”‚   â””â”€â”€ [Other test suites]     # 787 total tests âœ…
â”œâ”€â”€ Docs/
â”‚   â”œâ”€â”€ SCREENPLAY_UI_SPRINT_METHODOLOGY.md
â”‚   â”œâ”€â”€ SCREENPLAY_UI_DECISIONS.md
â”‚   â””â”€â”€ Previous/                # Archived documentation
â”œâ”€â”€ CLAUDE.md                    # AI assistant guide
â”œâ”€â”€ CHANGELOG.md                 # Version history
â”œâ”€â”€ AI_DEVELOPMENT_GUIDE.md      # Development patterns
â””â”€â”€ AI_REFERENCE.md              # Quick reference
```

## Development Phases

| Phase | Status | Description |
|-------|--------|-------------|
| **Phase 0** | âœ… Complete | Foundation and Planning |
| **Phase 1** | âœ… Complete | Core Provider System |
| **Phase 2** | âœ… Complete | Data Persistence Layer |
| **Phase 3** | âœ… Complete | Request Management System |
| **Phase 4** | âœ… Complete | Security and Credential Management |
| **Phase 5** | âœ… Complete | Default Provider Implementations |
| **Phase 6** | âœ… Complete | Typed Return Data |
| **Phase 7** | âœ… Complete | Test Coverage & Quality Assurance |
| **Phase 8** | ðŸ“‹ Planned | Sample Applications |
| **Phase 9** | ðŸ“‹ Planned | Documentation and Templates |
| **Phase 10** | ðŸ“‹ Planned | Integration and System Testing |
| **Phase 11** | ðŸ“‹ Planned | Beta Release and Community Validation |
| **Phase 12** | ðŸ“‹ Planned | v2.0 Release |

See [METHODOLOGY.md](METHODOLOGY.md) for detailed phase descriptions, quality gates, and testing requirements.

## License

This package is part of the TableReader project.

## Contributing

We welcome contributions from developers and AI code builders! Whether you're adding a new AI service provider, implementing custom data types, improving documentation, or fixing bugs, your contributions help make SwiftHablarÃ© better for everyone.

### How to Contribute

1. **Fork the repository** and create your branch from `main`
2. **Read the documentation**:
   - [REQUIREMENTS.md](REQUIREMENTS.md) - Complete requirements and architecture
   - [CONTRIBUTING.md](CONTRIBUTING.md) - Detailed contribution guidelines
   - Provider templates in `/Templates` directory
3. **Make your changes**:
   - Follow Swift API design guidelines
   - Add tests for new functionality
   - Update documentation as needed
4. **Ensure quality**:
   - All tests pass (`swift test`)
   - Code follows existing patterns and conventions
   - Documentation is clear and includes examples
5. **Submit a pull request** with a clear description of your changes

### What to Contribute

- **New AI Service Providers**: Add support for additional AI services
- **Custom Data Types**: Extend the framework to support new data formats
- **Documentation**: Improve guides, add examples, fix typos
- **Bug Fixes**: Fix issues and improve reliability
- **Tests**: Add test coverage for existing functionality
- **Examples**: Create sample apps demonstrating framework usage

### For AI Code Builders

This framework is designed to be extended by AI assistants like Claude and ChatGPT. We provide:
- Template files with clear TODO markers
- Comprehensive inline documentation
- Working examples for reference
- Automated tests to verify implementations

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines on creating providers and extending the framework.

## Community

- **Issues**: Report bugs or request features on [GitHub Issues](https://github.com/intrusive-memory/SwiftHablare/issues)
- **Discussions**: Ask questions and share ideas in [GitHub Discussions](https://github.com/intrusive-memory/SwiftHablare/discussions)
- **Pull Requests**: Review the contribution guidelines before submitting
